-*- outline -*-

* Pending (before it can be used for ANYTHING)

** Rename the functions in btree/forest/..

*** Current

_add_child: raw add child node to current node
 => add_child_nocheck

add_child: add child node to current node, possibly split (and return new node)
 = same name?

add: add leaf node wherever it wants to be; also returns the root always
 => add_to_tree

removes are mostly similar, although they do not return anything

_remove_child:
 => remove_child_nocheck

remove_child:
 = same name?

remove:
 => remove_from_tree

** Fix multi-worker model (sqlite not happy about distinct threads, sigh)

** Better perf benchmarks.. :p

** Add missing functionality to forest module (e.g. remove API?)

** Write more thorough filesystem tests to test_ops or elsewhere

** Correct readdir semantics

mutation should not result in non-mutated files being omitted/returned
twice (this should be trivially given we iterate automatically by filename
within the tree order?)

* Pending 2 (before it can be used for ANYTHING); TBD P2 in code

* Pending before it can be used for single-user, multiple-installations

** Implement tree remote protocol

essentially have to store locally from leaves onward; otherwise refcnts are
wrong. however, how does partial tree work in this case? it does not,
really.

so the remoting will have two modes:

- weak references ('cache') + remote access on demand

- strong references + stored remote trees to be merged
 - should store leaves first so we can correctly handle dependencies..

** Implement tree merge code (SHOULD be straightforward, but who knows)

*** Bare bones code IS there, but it needs unit tests

* Pending before it can be used (reliably) for multi-user

** Sticky bit

* Pending (eventually)

** Check/test

*** Insertion to various places (should work but who knows)
*** Reading in clever and unexpected ways (should work but who knows)

** Security improvements

*** Add support for rewriting block ids (e.g. encode_id, decode_id) on the way to disk as well.

Currently, the block ids are actually based on the plaintext, but design
does not really force it (just current implementation limitation). Using
encrypted block ids would be better.

** Consider if CBORPickler should also support e.g. IntEnum as argument

** Work out how sharing of storage backends works

The main question is when to rm blocks for real. If we have exclusive
access to a storage, can rm them if there is no tree (either root-based
forest or inode based forest) referring to them.

Persisting inode-based references (in-memory construct) seems like
undesirable design (causes more disk churn). Ways around it:

*** (Always) exclusive use of storage backend

No need to worry about other writers => no need to do the churn to actually
disk.

*** No cleanups when shared

With one main writer, can have it get exclusive (r+w) lock, and drop it
infrequently or on demand if there are other potential writers. While
multiple writers are present, no cleanups.

*** Shared cleanups

- post read-only notice

- wait for other writers to _increment_ their inodes' reference counts to
  disk (and switch to read-only mode)

- rm blocks based on update dreference counts

- remove read-only notice

Electing the cleaner to be the one with most in-memory references seems
sensible but possibly minor optimization.

** Rethink if inodestore <> forest abstraction is good
